{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Stemming and Lemmatization**"
      ],
      "metadata": {
        "id": "_huwre4bBNQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Aim** : To understand the concept of stemming and lemmatization"
      ],
      "metadata": {
        "id": "u07OkhsUCfHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tools** : Jupyter / any editor of python"
      ],
      "metadata": {
        "id": "l9xs6U1NHBgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Library** : NLTK"
      ],
      "metadata": {
        "id": "iqPBT10pHEo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Method** : Using already available functions like:\n",
        "\n",
        "**Stemming**\n",
        "1. PorterStemmer\n",
        "2. LancasterStemmer\n",
        "3. RegexpStemmer\n",
        "4. SnowballStemmer\n",
        "\n",
        "**Lemmatization**\n",
        "1. WordNetLemmatizer"
      ],
      "metadata": {
        "id": "NPiSFocYHTGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ye mat likh dena**\n",
        "\n",
        "https://www.tutorialspoint.com/natural_language_toolkit/natural_language_toolkit_stemming_lemmatization.htm"
      ],
      "metadata": {
        "id": "yfz2iBRZEo7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming**\n",
        "\n",
        "Stemming is a technique used to extract the base form of the words by removing affixes from them. It is just like cutting down the branches of a tree to its stems. For example, the stem of the words eating, eats, eaten is eat.\n",
        "\n",
        "Search engines use stemming for indexing the words. That’s why rather than storing all forms of a word, a search engine can store only the stems. In this way, stemming reduces the size of the index and increases retrieval accuracy."
      ],
      "metadata": {
        "id": "lF6bDiLwCAOZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG_EqpFrAKA-"
      },
      "outputs": [],
      "source": [
        "import nltk.corpus\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import RegexpStemmer\n",
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Porter stemming algorithm**\n",
        "\n",
        "It is one of the most common stemming algorithms which is basically designed to remove and replace well-known suffixes of English words. This class knows several regular word forms and suffixes with the help of which it can transform the input word to a final stem. The resulting stem is often a shorter word having the same root meaning."
      ],
      "metadata": {
        "id": "DR4rbWRXI6eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_stemmer = PorterStemmer()\n",
        "word_stemmer.stem('writing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bwDTQOqLJ7zv",
        "outputId": "3e2a28ce-fb51-4dd3-aac7-84ebe8d5ae48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'write'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_stemmer.stem('eating')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "54G7yIiiKxrX",
        "outputId": "bd8cf169-4db8-42df-e80b-d5e8621df25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Lancaster stemming algorithm**\n",
        "\n",
        "It was developed at Lancaster University and it is another very common stemming algorithms.\n",
        "\n",
        "With the help of **LancasterStemmer** we can easily implement Lancaster Stemmer algorithms for the word we want to stem."
      ],
      "metadata": {
        "id": "ySGxhz3QKDQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Lanc_stemmer = LancasterStemmer()\n",
        "Lanc_stemmer.stem('eats')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_f7zSXRxKpp2",
        "outputId": "eee5a85e-fdec-40df-ae8d-313a73ef4691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'eat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Regular Expression stemming algorithm**\n",
        "\n",
        "With the help of this stemming algorithm, we can construct our own stemmer.\n",
        "\n",
        "It basically takes a single regular expression and removes any prefix or suffix that matches the expression."
      ],
      "metadata": {
        "id": "eIHBtV6JK2NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n",
        "words = ['connecting','connect','factionally','faction',\"consult\",\"consulation\"]\n",
        "for word in words:\n",
        "  print(word,\"--->\",regexp.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3BlFBwwLMAW",
        "outputId": "6dd0bb81-ac1b-434b-d0ac-276f26bd5d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "connecting ---> connect\n",
            "connect ---> connect\n",
            "factionally ---> factionally\n",
            "faction ---> faction\n",
            "consult ---> consult\n",
            "consulation ---> consulation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Snowball stemming algorithm**\n",
        "\n",
        "**SnowballStemmer** supports 15 non-English languages. In order to use this steaming class, we need to create an instance with the name of the language we are using and then call the stem() method."
      ],
      "metadata": {
        "id": "14uCMnMxMcC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "SnowballStemmer.languages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUsUNj9_My0G",
        "outputId": "a6af4300-5f5b-4b48-b1b2-440738aa387f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('arabic',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'hungarian',\n",
              " 'italian',\n",
              " 'norwegian',\n",
              " 'porter',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'spanish',\n",
              " 'swedish')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "French_stemmer = SnowballStemmer('french')\n",
        "French_stemmer.stem ('Bonjoura')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NKsfV_kVM64u",
        "outputId": "927f0d03-9f4f-4502-b94b-3a79e51566ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bonjour'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatization**\n",
        "\n",
        "Lemmatization technique is like stemming. The output we will get after lemmatization is called ‘lemma’, which is a root word rather than root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing.\n",
        "\n",
        "**WordNetLemmatizer** class is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma."
      ],
      "metadata": {
        "id": "-m3nASdpCz2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "  \n",
        "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\"))\n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
        "\n",
        "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "336pHVpyNZFI",
        "outputId": "82f40b16-7b61-4416-cd90-663a2dbea6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rocks : rock\n",
            "corpora : corpus\n",
            "better : good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "****\n",
        "**POS tagging or Chunking**\n",
        "\n",
        "https://www.geeksforgeeks.org/python-lemmatization-approaches-with-examples/"
      ],
      "metadata": {
        "id": "fWJjQJ0iOQTO"
      }
    }
  ]
}